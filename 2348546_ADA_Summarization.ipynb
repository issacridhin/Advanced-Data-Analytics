{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-L34SPyR0Y0",
        "outputId": "6e903ab7-d0f1-4b4e-a4fd-e1eb2491fda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.31.0)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.6.2)\n",
            "Building wheels for collected packages: breadability, docopt\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21693 sha256=fc8ce2c741873ef9780874eba743eac76f39c59ee5da1a7246f8fb96db673abe\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=b3c74b06b5abbb2991f9332f8258017b8954e266d73cca61b3170653b1e6b076\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built breadability docopt\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sumy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w89XO39Sfhl",
        "outputId": "cc0b5ab1-1dcd-4de8-b1a4-9b2662875392"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer"
      ],
      "metadata": {
        "id": "-pj6b__PSveu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w1aCNFhSw79",
        "outputId": "30b5d1fb-8a10-4155-b303-0774d8cede20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "WUmyB1IxS0D3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"/content/CrimeCase.txt\""
      ],
      "metadata": {
        "id": "7ZuK0LCBTMpo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parser and Tokenizer\n",
        "parser = PlaintextParser.from_file(text, Tokenizer(\"english\"))\n",
        "\n",
        "#TextRank Summarizer\n",
        "TRsummarizer = TextRankSummarizer()\n",
        "LRsummarizer = LexRankSummarizer()\n",
        "LSsummarizer = LsaSummarizer()\n",
        "\n",
        "#Generate Summary\n",
        "#Summarize to 3 Sentences\n",
        "TRsummary = TRsummarizer(parser.document, 3)\n",
        "LRsummary = LRsummarizer(parser.document, 3)\n",
        "LSsummary = LSsummarizer(parser.document, 3)\n",
        "sum_sentence = \"\"\n",
        "\n",
        "#print summart\n",
        "for sentence in TRsummary:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivtc5WfXTqTK",
        "outputId": "24fa898f-bd21-4e63-85d3-6ff8cfddb90c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section 302 - Indian Penal Code (IPC) - Murder Section 397 - IPC - Robbery, or dacoity, with attempt to cause death or grievous hurt Section 411 - IPC - Dishonestly receiving stolen property Summary of Facts: On the night of October 15, 2021, the defendant, Rajesh Kumar, along with two accomplices, forcibly entered the residence of the victim, Mr. Shyam Lal, located at 45, Andheri East, Mumbai.\n",
            "The prosecution emphasized the brutality of the murder and the overwhelming evidence of the defendant's guilt.\n",
            "Additionally, he received ten years of rigorous imprisonment for the robbery charge under Section 397 of the IPC and five years for receiving stolen property under Section 411 of the IPC, with sentences to run concurrently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the summaries to different variables\n",
        "tr_summary_text = \"\"\n",
        "lr_summary_text = \"\"\n",
        "ls_summary_text = \"\"\n",
        "bert_summary_text = \"\"\n",
        "\n",
        "# Extract the text from each summary object\n",
        "for sentence in TRsummary:\n",
        "    tr_summary_text += \" \" + str(sentence)\n",
        "for sentence in LRsummary:\n",
        "    lr_summary_text += \" \" + str(sentence)\n",
        "for sentence in LSsummary:\n",
        "    ls_summary_text += \" \" + str(sentence)\n",
        "bert_summary_text = BERTsummary[0]['summary_text']\n",
        "\n",
        "# Print the summaries\n",
        "print(\"TextRank Summary:\", tr_summary_text)\n",
        "print(\"LexRank Summary:\", lr_summary_text)\n",
        "print(\"LSA Summary:\", ls_summary_text)\n",
        "print(\"BERT Summary:\", bert_summary_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP66pwQFUhB_",
        "outputId": "e4033b54-507e-4502-ca68-42cb4d268bf9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextRank Summary:  Section 302 - Indian Penal Code (IPC) - Murder Section 397 - IPC - Robbery, or dacoity, with attempt to cause death or grievous hurt Section 411 - IPC - Dishonestly receiving stolen property Summary of Facts: On the night of October 15, 2021, the defendant, Rajesh Kumar, along with two accomplices, forcibly entered the residence of the victim, Mr. Shyam Lal, located at 45, Andheri East, Mumbai. The prosecution emphasized the brutality of the murder and the overwhelming evidence of the defendant's guilt. Additionally, he received ten years of rigorous imprisonment for the robbery charge under Section 397 of the IPC and five years for receiving stolen property under Section 411 of the IPC, with sentences to run concurrently.\n",
            "LexRank Summary:  Based on eyewitness accounts and forensic evidence, Rajesh Kumar was apprehended within a week and found in possession of several items identified as stolen from the Lal residence. Prosecution Argument: The prosecution relied on the strong testimonial evidence of Mrs. Kamla Lal, supported by forensic evidence and CCTV footage. Verdict: The court found Rajesh Kumar guilty on all charges, including murder, robbery, and possession of stolen property.\n",
            "LSA Summary:  They then proceeded to loot the house, taking cash, jewelry, and other valuable items. Based on eyewitness accounts and forensic evidence, Rajesh Kumar was apprehended within a week and found in possession of several items identified as stolen from the Lal residence. Verdict: The court found Rajesh Kumar guilty on all charges, including murder, robbery, and possession of stolen property.\n",
            "BERT Summary:  Rajesh Kumar was found guilty of murder, robbery, and possession of stolen property . He was sentenced to life imprisonment for the murder charge under Section 302 of the IPC .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizer result verification"
      ],
      "metadata": {
        "id": "FBwZxKeIW9Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDs0PI_1W1wg",
        "outputId": "9c8f3c9c-d0b9-4e75-dc1f-c7352d1f9e64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=3577cd860a67aca9f16776812ffc8999bfb1fb14a0e42749b22f8486400e5e70\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 gram will take one word\n",
        "\n",
        "2 gram will take two word\n",
        "\n",
        ".........................\n",
        "\n",
        "n gram will take n words\n"
      ],
      "metadata": {
        "id": "KpKcL344YHXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score"
      ],
      "metadata": {
        "id": "TjA2cx_hYObl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Intitialize the ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "#Calculate the ROUGE scores\n",
        "ROUGEscore = scorer.score(tr_summary_text, lr_summary_text)\n",
        "\n",
        "#print the ROUGE score\n",
        "for key, value in ROUGEscore.items():\n",
        "    print(f\"{key}: Precision: {value.precision:.2f}, Recall: {value.recall:.2f}, F1-score: {value.fmeasure:.2f}\")\n",
        "\n",
        "#print the BLEU score\n",
        "score = sentence_bleu(tr_summary_text, lr_summary_text)\n",
        "print(\"BLEU Score:\", score)\n",
        "\n",
        "#print the METEOR score\n",
        "# score = meteor_score(tr_summary_text, lr_summary_text)\n",
        "# print(\"METEOR Score:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ObqPxBqaEk_",
        "outputId": "fbd540c2-7111-4f72-a02c-b74c2e1cdc58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1: Precision: 0.33, Recall: 0.19, F1-score: 0.24\n",
            "rouge2: Precision: 0.08, Recall: 0.04, F1-score: 0.06\n",
            "rougeL: Precision: 0.24, Recall: 0.14, F1-score: 0.18\n",
            "BLEU Score: 9.540990075903533e-232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from transformers import pipeline\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the summarization pipeline\n",
        "bert_summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Read the text file\n",
        "with open(\"/content/CrimeCase.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Parser and Tokenizer\n",
        "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "# TextRank Summarizer\n",
        "TRsummarizer = TextRankSummarizer()\n",
        "LRsummarizer = LexRankSummarizer()\n",
        "LSsummarizer = LsaSummarizer()\n",
        "\n",
        "# Generate Summary\n",
        "# Summarize to 3 Sentences\n",
        "TRsummary = TRsummarizer(parser.document, 3)\n",
        "LRsummary = LRsummarizer(parser.document, 3)\n",
        "LSsummary = LSsummarizer(parser.document, 3)\n",
        "BERTsummary = bert_summarizer(text, max_length=150, min_length=30, do_sample=False)\n",
        "\n",
        "# Extract the text from each summary object\n",
        "tr_summary_text = \" \".join([str(sentence) for sentence in TRsummary])\n",
        "lr_summary_text = \" \".join([str(sentence) for sentence in LRsummary])\n",
        "ls_summary_text = \" \".join([str(sentence) for sentence in LSsummary])\n",
        "bert_summary_text = BERTsummary[0]['summary_text']\n",
        "\n",
        "# Initialize the ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Calculate the ROUGE scores\n",
        "rouge_scores = {\n",
        "    \"TR_vs_BERT\": scorer.score(tr_summary_text, bert_summary_text),\n",
        "    \"LR_vs_BERT\": scorer.score(lr_summary_text, bert_summary_text),\n",
        "    \"LS_vs_BERT\": scorer.score(ls_summary_text, bert_summary_text)\n",
        "}\n",
        "\n",
        "# Print the ROUGE scores for BERT\n",
        "for comparison, scores in rouge_scores.items():\n",
        "    print(f\"ROUGE scores for {comparison}:\")\n",
        "    for key, value in scores.items():\n",
        "        print(f\"  {key}: Precision: {value.precision:.2f}, Recall: {value.recall:.2f}, F1-score: {value.fmeasure:.2f}\")\n",
        "\n",
        "# Tokenize summaries for BLEU and METEOR scores\n",
        "tr_summary_tokens = nltk.word_tokenize(tr_summary_text)\n",
        "lr_summary_tokens = nltk.word_tokenize(lr_summary_text)\n",
        "ls_summary_tokens = nltk.word_tokenize(ls_summary_text)\n",
        "bert_summary_tokens = nltk.word_tokenize(bert_summary_text)\n",
        "\n",
        "# Calculate and print the BLEU scores for BERT\n",
        "bleu_scores = {\n",
        "    \"TR_vs_BERT\": sentence_bleu([tr_summary_tokens], bert_summary_tokens),\n",
        "    \"LR_vs_BERT\": sentence_bleu([lr_summary_tokens], bert_summary_tokens),\n",
        "    \"LS_vs_BERT\": sentence_bleu([ls_summary_tokens], bert_summary_tokens)\n",
        "}\n",
        "\n",
        "for comparison, score in bleu_scores.items():\n",
        "    print(f\"BLEU score for {comparison}: {score:.2f}\")\n",
        "\n",
        "# Calculate and print the METEOR scores for BERT\n",
        "meteor_scores = {\n",
        "    \"TR_vs_BERT\": meteor_score([tr_summary_tokens], bert_summary_tokens),\n",
        "    \"LR_vs_BERT\": meteor_score([lr_summary_tokens], bert_summary_tokens),\n",
        "    \"LS_vs_BERT\": meteor_score([ls_summary_tokens], bert_summary_tokens)\n",
        "}\n",
        "\n",
        "for comparison, score in meteor_scores.items():\n",
        "    print(f\"METEOR score for {comparison}: {score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3rfEk4XNDk9",
        "outputId": "474b2de0-1bcc-46b2-b5d0-844fd4d84283"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE scores for TR_vs_BERT:\n",
            "  rouge1: Precision: 0.79, Recall: 0.20, F1-score: 0.32\n",
            "  rouge2: Precision: 0.39, Recall: 0.10, F1-score: 0.15\n",
            "  rougeL: Precision: 0.55, Recall: 0.14, F1-score: 0.22\n",
            "ROUGE scores for LR_vs_BERT:\n",
            "  rouge1: Precision: 0.59, Recall: 0.25, F1-score: 0.35\n",
            "  rouge2: Precision: 0.29, Recall: 0.12, F1-score: 0.17\n",
            "  rougeL: Precision: 0.41, Recall: 0.18, F1-score: 0.25\n",
            "ROUGE scores for LS_vs_BERT:\n",
            "  rouge1: Precision: 0.59, Recall: 0.28, F1-score: 0.38\n",
            "  rouge2: Precision: 0.29, Recall: 0.14, F1-score: 0.18\n",
            "  rougeL: Precision: 0.41, Recall: 0.20, F1-score: 0.27\n",
            "BLEU score for TR_vs_BERT: 0.00\n",
            "BLEU score for LR_vs_BERT: 0.09\n",
            "BLEU score for LS_vs_BERT: 0.11\n",
            "METEOR score for TR_vs_BERT: 0.16\n",
            "METEOR score for LR_vs_BERT: 0.24\n",
            "METEOR score for LS_vs_BERT: 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    }
  ]
}